{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions - Problem 3\n",
    "Get all the flights which are departed late but arrived early (**IsArrDelayed is NO**).\n",
    "* Output should contain - **FlightCRSDepTime**, **UniqueCarrier**, **FlightNum**, **Origin**, **Dest**, **DepDelay**, **ArrDelay**\n",
    "* **FlightCRSDepTime** need to be computed using **Year**, **Month**, **DayOfMonth**, **CRSDepTime**\n",
    "* **FlightCRSDepTime** should be displayed using **YYYY-MM-dd HH:mm** format.\n",
    "* Output should be sorted by **FlightCRSDepTime** and then by the difference between **DepDelay** and **ArrDelay**\n",
    "* Also get the count of such flights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Basic Transformations'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtraffic.select('Year', 'Month', 'DayOfMonth', 'CRSDepTime').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(2008, 1, 23, 700),\n",
    "     (2008, 1, 10, 1855),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(l, \"Year INT, Month INT, DayOfMonth INT, DepTime INT\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring\n",
    "df.select(substring(col('DepTime'), -2, 2)). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"DepTime\", date_format(lpad('DepTime', 4, \"0\"), 'HH:mm')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(substring(col('DepTime'), 1, length(col('DepTime').cast('string')))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, concat, lpad, sum, expr\n",
    "\n",
    "flightsFiltered = airtraffic. \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\"). \\\n",
    "    select(concat(\"Year\", lit(\"-\"), \n",
    "                  lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\"), lit(\" \"),\n",
    "                  lpad(\"CRSDepTime\", 4, \"0\")\n",
    "                 ).alias(\"FlightCRSDepTime\"),\n",
    "           \"UniqueCarrier\", \"FlightNum\", \"Origin\", \n",
    "           \"Dest\", \"DepDelay\", \"ArrDelay\"\n",
    "          ). \\\n",
    "    orderBy(\"FlightCRSDepTime\", col(\"DepDelay\") - col(\"ArrDelay\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Getting Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, concat, lpad, sum, expr\n",
    "\n",
    "flightsFiltered = airtraffic. \\\n",
    "    filter(\"IsDepDelayed = 'YES' AND IsArrDelayed = 'NO'\"). \\\n",
    "    select(concat(\"Year\", lit(\"-\"), \n",
    "                  lpad(\"Month\", 2, \"0\"), lit(\"-\"), \n",
    "                  lpad(\"DayOfMonth\", 2, \"0\"), lit(\" \"),\n",
    "                  lpad(\"CRSDepTime\", 4, \"0\")\n",
    "                 ).alias(\"FlightCRSDepTime\"),\n",
    "           \"UniqueCarrier\", \"FlightNum\", \"Origin\", \n",
    "           \"Dest\", \"DepDelay\", \"ArrDelay\"\n",
    "          ). \\\n",
    "    count()\n",
    "\n",
    "flightsFiltered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
